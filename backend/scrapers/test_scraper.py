#!/usr/bin/env python3
"""
Test Script for AgiNet Web Scraping System
Demonstrates scraping functionality with sample data
"""

import json
import time
from agri_scraper import AgriScraper
from data_integrator import AgiNetDataIntegrator

def test_basic_scraping():
    """Test basic scraping functionality"""
    print("ğŸŒ¾ Testing Basic Scraping...")
    
    scraper = AgriScraper()
    
    # Generate sample data for testing
    products = scraper.generate_sample_data(20)
    
    print(f"âœ… Generated {len(products)} sample products")
    
    # Display sample products
    print("\nğŸ“¦ Sample Products:")
    for i, product in enumerate(products[:5]):
        print(f"{i+1}. {product.name}")
        print(f"   Price: {product.price}")
        print(f"   Category: {product.category}")
        print(f"   Brand: {product.brand}")
        print()
    
    # Save to JSON
    json_file = "test_products.json"
    if scraper.save_to_json(products, json_file):
        print(f"âœ… Products saved to {json_file}")
        return json_file
    else:
        print("âŒ Failed to save products")
        return None

def test_data_integration(json_file):
    """Test database integration"""
    print("\nğŸ”„ Testing Data Integration...")
    
    integrator = AgiNetDataIntegrator("test_database.db")
    
    # Show initial stats
    initial_stats = integrator.get_database_stats()
    print(f"ğŸ“Š Initial Database Stats: {initial_stats}")
    
    # Integrate data
    result = integrator.integrate_scraped_data(json_file)
    print(f"âœ… Integration Result: {result}")
    
    # Show final stats
    final_stats = integrator.get_database_stats()
    print(f"ğŸ“Š Final Database Stats: {final_stats}")
    
    # Export for frontend
    export_file = "test_export.json"
    if integrator.export_to_json(export_file):
        print(f"âœ… Database exported to {export_file}")
        return export_file
    else:
        print("âŒ Export failed")
        return None

def test_json_structure(json_file):
    """Test JSON file structure"""
    print(f"\nğŸ“‹ Testing JSON Structure: {json_file}")
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… JSON file loaded successfully")
        print(f"ğŸ“Š Structure:")
        
        if isinstance(data, dict):
            for key, value in data.items():
                if isinstance(value, list):
                    print(f"   {key}: {len(value)} items")
                else:
                    print(f"   {key}: {value}")
                    
            # Show sample product structure
            if 'products' in data and data['products']:
                print(f"\nğŸ“¦ Sample Product Structure:")
                sample_product = data['products'][0]
                for key, value in sample_product.items():
                    print(f"   {key}: {value}")
                    
        return True
        
    except Exception as e:
        print(f"âŒ JSON structure test failed: {e}")
        return False

def performance_test():
    """Test scraping performance"""
    print("\nâš¡ Performance Test...")
    
    scraper = AgriScraper()
    
    # Test different data sizes
    sizes = [10, 50, 100]
    
    for size in sizes:
        start_time = time.time()
        products = scraper.generate_sample_data(size)
        generation_time = time.time() - start_time
        
        start_time = time.time()
        scraper.save_to_json(products, f"perf_test_{size}.json")
        save_time = time.time() - start_time
        
        print(f"ğŸ“Š Size {size}:")
        print(f"   Generation: {generation_time:.3f}s")
        print(f"   Save: {save_time:.3f}s")
        print(f"   Rate: {size/generation_time:.1f} products/sec")

def cleanup_test_files():
    """Clean up test files"""
    import os
    import glob
    
    test_files = [
        "test_products.json",
        "test_database.db",
        "test_export.json"
    ] + glob.glob("perf_test_*.json")
    
    for file in test_files:
        try:
            if os.path.exists(file):
                os.remove(file)
                print(f"ğŸ—‘ï¸ Removed {file}")
        except Exception as e:
            print(f"âš ï¸ Could not remove {file}: {e}")

def main():
    """Run all tests"""
    print("ğŸ§ª AgiNet Scraping System Test Suite")
    print("=" * 50)
    
    try:
        # Test 1: Basic scraping
        json_file = test_basic_scraping()
        if not json_file:
            print("âŒ Basic scraping test failed")
            return
        
        # Test 2: JSON structure
        if not test_json_structure(json_file):
            print("âŒ JSON structure test failed")
            return
        
        # Test 3: Data integration
        export_file = test_data_integration(json_file)
        if not export_file:
            print("âŒ Data integration test failed")
            return
        
        # Test 4: Export structure
        if not test_json_structure(export_file):
            print("âŒ Export structure test failed")
            return
        
        # Test 5: Performance
        performance_test()
        
        print("\nğŸ‰ All tests completed successfully!")
        print("\nğŸ“‹ Test Summary:")
        print("   âœ… Basic scraping")
        print("   âœ… JSON structure validation")
        print("   âœ… Database integration")
        print("   âœ… Data export")
        print("   âœ… Performance testing")
        
        # Show final file sizes
        import os
        print(f"\nğŸ“ Generated Files:")
        for file in [json_file, export_file]:
            if os.path.exists(file):
                size = os.path.getsize(file)
                print(f"   {file}: {size:,} bytes")
        
    except Exception as e:
        print(f"âŒ Test suite failed: {e}")
        
    finally:
        # Cleanup
        cleanup_choice = input("\nğŸ—‘ï¸ Clean up test files? (y/n): ").lower()
        if cleanup_choice == 'y':
            cleanup_test_files()
            print("âœ… Cleanup completed")

if __name__ == "__main__":
    main()
